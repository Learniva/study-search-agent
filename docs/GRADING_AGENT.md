# AI Grading Agent

Autonomous grading with rubric evaluation, consistency checking, and quality assurance.

## Overview

AI-powered academic grading for essays, code, and MCQs with built-in quality control.

**Key Capabilities:**
- âœï¸ Essay grading with rubrics
- ðŸ’» Code review and analysis
- âœ… MCQ auto-grading
- ðŸ“Š Custom rubric evaluation
- ðŸ’¬ Detailed feedback generation
- ðŸŽ¯ Consistency checking
- ðŸ” Bias detection

**Tools:** Essay Grading â€¢ Code Review â€¢ MCQ Auto-grading â€¢ Rubric Evaluation â€¢ Feedback Generation

## Architecture

```
Request â†’ [Analyze] â†’ [Detect Complexity] â†’ Simple or Complex?
             â†“              â†“                      â†“
      (Type/Length)  [Direct Tool]          [Multi-Criteria Plan]
                           â†“                      â†“
                    [Consistency Check] â† â”€ â”€ [Execute Loop]
                           â†“
                    [Self-Reflect] â†’ Flag / Improve / Finalize
```

## Features

| Feature | Details |
|---------|---------|
| **Analysis** | Auto-detect: Type â€¢ Length â€¢ Complexity â€¢ Language |
| **Routing** | Pattern-based (`code`â†’review, `mcq`â†’grade, defaultâ†’essay) |
| **Consistency** | Rubric alignment â€¢ Score balance â€¢ Bias detection |
| **Confidence** | >80% finalize, 60-80% improve, <60% flag |
| **Reflection** | Re-evaluate if low confidence (up to 3 iterations) |

## Tools

| Tool | Purpose | Speed |
|------|---------|-------|
| **Essay Grading** | Rubric-based evaluation | 8-12s |
| **Code Review** | Programming analysis | 10-15s |
| **MCQ Grading** | Auto-scoring | 3-5s |
| **Rubric Eval** | Custom criteria | 12-20s |
| **Feedback Gen** | Constructive comments only | 5-8s |

## Usage

### Basic

```python
from agents.grading import GradingAgent

agent = GradingAgent()
result = agent.query(
    question="Grade this essay: [text]",
    professor_id="prof123",
    student_id="stu456"
)
```

### Async

```python
result = await agent.aquery(
    question="Review this code: [code]",
    professor_id="prof123"
)
```

### Custom Rubric

```python
rubric = {
    "submission": "Essay...",
    "rubric": {
        "criteria": {
            "thesis": {"weight": 0.3, "description": "..."},
            "evidence": {"weight": 0.4, "description": "..."}
        }
    }
}
result = agent.query(question=json.dumps(rubric), professor_id="prof123")
```

## Output Format

```
Grade: 85/100

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ðŸ“Š Breakdown: Thesis (22/25) â€¢ Evidence (26/30) â€¢ Organization (18/20)

ðŸ’ª Strengths: Well-researched, clear writing
ðŸ“ˆ Improvements: Add primary sources, fix citations

âœ… Confidence: 85% â€¢ Consistency: 92%
âš ï¸  AI-generated - Review and adjust as needed
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
```

**If flagged:** `âš ï¸ FLAGGED FOR REVIEW â€¢ Reasons: Low confidence (58%), unusual format`

## State

```python
{
    "question": str,
    "professor_id": str,
    "student_id": str,
    "grading_type": str,          # essay/code/mcq
    "is_complex_grading": bool,
    "grading_confidence": float,
    "consistency_score": float,
    "needs_human_review": bool,
    "final_answer": str
}
```

## Performance

| Metric | Value |
|--------|-------|
| Accuracy vs humans | 87% |
| Consistency (rubric) | 94% |
| Bias detection | 96% |
| High confidence rate | 65% |
| Flagged rate | 7% |

## ML Features

**Rubric Adaptation:** Learns from professor feedback to improve future gradings

**Consistency Tracking:** Learns professor-specific patterns, strictness, preferences

```python
# Submit feedback to improve
adaptive_rubric_manager.record_feedback(
    rubric_id="essay_general",
    ai_grade=75,
    actual_grade=82
)
```

## Configuration

```bash
# Required
GOOGLE_API_KEY=xxx
DATABASE_URL=postgresql+asyncpg://...

# Performance
MAX_GRADING_ITERATIONS=3
TEMP_GRADING=0.3                # Low for consistency
```

## Workflows

**Simple:** Analyze â†’ Route â†’ Execute â†’ Check â†’ Reflect â†’ Finalize

**Complex:** Analyze â†’ Plan Multi-Criteria â†’ Execute Loop â†’ Check â†’ Reflect â†’ Finalize

## Troubleshooting

| Problem | Solution |
|---------|----------|
| Low confidence | Use specific rubrics, provide examples |
| Inconsistent grading | Use predefined rubrics, enable ML |
| Too many flags | Adjust threshold, improve rubric clarity |

## Examples

```python
# Essay with rubric
agent.query("Grade using essay_general rubric: [text]")

# Code review
agent.query("Review this code: def bubble_sort(arr): ...")

# MCQ grading  
agent.query("Grade MCQ: 1. 2+2? Answer: 4 ...")

# Feedback only (no score)
agent.query("Provide feedback on: [text]")
```

---

**See also:** [Study Agent](STUDY_AGENT.md) â€¢ [Supervisor Agent](SUPERVISOR_AGENT.md)
